nohup: ignoring input
Traceback (most recent call last):
  File "/home/pengyaoguang/program_learn/program/shengli/3D_net6_3.py", line 39, in <module>
    model=net(2,1,True,True).to(device)
  File "/home/pengyaoguang/.conda/envs/pytorch3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1160, in to
    return self._apply(convert)
  File "/home/pengyaoguang/.conda/envs/pytorch3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/home/pengyaoguang/.conda/envs/pytorch3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/home/pengyaoguang/.conda/envs/pytorch3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/home/pengyaoguang/.conda/envs/pytorch3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 833, in _apply
    param_applied = fn(param)
  File "/home/pengyaoguang/.conda/envs/pytorch3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1158, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

